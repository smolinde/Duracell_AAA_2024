{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab6d6c2d-3d6a-452b-9c2c-468c39da5ff3",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5461395-87c3-44d5-aaea-09a379c73d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('merged_df_8.pkl', 'rb') as file:\n",
    "    df8 = pickle.load(file)\n",
    "with open('merged_df_7.pkl', 'rb') as file:\n",
    "    df7 = pickle.load(file)\n",
    "with open('merged_df_6.pkl', 'rb') as file:\n",
    "    df6 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48660b4b-011c-4746-bb01-c80db6b9f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataset(df, timebucket):\n",
    "    # Create a copy of the dataframe\n",
    "    df_copy = df.copy()\n",
    "    # Add the time bucket column\n",
    "    df_copy['time_bucket'] = pd.cut(df_copy['hour_of_day'], bins=range(-1, 25, timebucket), labels=False)\n",
    "    # Take mean of weather data by time bucket\n",
    "    df_copy['temperature'] = df_copy.groupby(['time_bucket', 'date'])['temperature'].transform('mean')\n",
    "    df_copy['dew_point'] = df_copy.groupby(['time_bucket', 'date'])['dew_point'].transform('mean')\n",
    "    df_copy['humidity'] = df_copy.groupby(['time_bucket', 'date'])['humidity'].transform('mean')\n",
    "    df_copy['wind_speed'] = df_copy.groupby(['time_bucket', 'date'])['wind_speed'].transform('mean')\n",
    "    df_copy['wind_gust'] = df_copy.groupby(['time_bucket', 'date'])['wind_gust'].transform('mean')\n",
    "    df_copy['pressure'] = df_copy.groupby(['time_bucket', 'date'])['pressure'].transform('mean')\n",
    "    df_copy['precipitation_rate'] = df_copy.groupby(['time_bucket', 'date'])['precipitation_rate'].transform('mean')\n",
    "    # Aggregate the demand\n",
    "    demand = df_copy.groupby(['date', 'time_bucket', 'hex_id']).size().reset_index(name='demand')\n",
    "    df_copy.drop(columns=[\"demand\"], inplace = True)\n",
    "    # Merge the demand back into the original DataFrame, dropping duplicates\n",
    "    df_copy = df_copy.merge(demand, on=['hex_id', 'date', 'time_bucket'], how='left')\n",
    "    df_copy = df_copy.drop_duplicates(subset=['hex_id', 'date', 'time_bucket'])\n",
    "    df_copy.drop(columns=['hour_of_day'])\n",
    "    s\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3960e98-dc3d-4abc-8b2c-c2dbdcc0d8ec",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bcad64-af05-44e2-b88e-0637947bf823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainsvmmodel(X, y, maxiter, splitratio, kernel):\n",
    "    \n",
    "    # 1) train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=splitratio)\n",
    "\n",
    "    # 2) scale and encoder\n",
    "    column_transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('hex', OneHotEncoder(handle_unknown='ignore'), ['hex_id']),\n",
    "            ('scale', StandardScaler(), X.columns.difference(['hex_id', 'date']))\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "    \n",
    "    svm_reg = make_pipeline(column_transformer, SVR(kernel=kernel, max_iter = maxiter))\n",
    "\n",
    "    # 3) Grid search for best parameters\n",
    "    if kernel == 'linear':\n",
    "        param_grid = {\n",
    "            'svr__C': [0.1, 1, 10, 100, 1000],\n",
    "            'svr__epsilon': [0.0001, 0.001, 0.1, 0.2, 0.5, 0.9]\n",
    "        }\n",
    "    else:\n",
    "        param_grid = {\n",
    "            'svr__C': [0.1, 1, 10, 100, 1000],\n",
    "            'svr__gamma': ['auto', 'scale'],\n",
    "            'svr__epsilon': [0.0001, 0.001, 0.1, 0.2, 0.5, 0.9]\n",
    "        }\n",
    "    \n",
    "    \n",
    "    grid_search = GridSearchCV(svm_reg, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_params =grid_search.best_params_\n",
    "\n",
    "    # 4) best model with optimal parameters\n",
    "    if kernel=='linear':\n",
    "        best_model = SVR(kernel=kernel,epsilon=best_params['svr__epsilon'], C=best_params['svr__C'], max_iter=maxiter)\n",
    "    else:\n",
    "        best_model = SVR(kernel=kernel,gamma=best_params['svr__gamma'],epsilon=best_params['svr__epsilon'], C=best_params['svr__C'], max_iter=maxiter)\n",
    "\n",
    "    # 5) train best model\n",
    "    best_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 6) evaluate model \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
    "    r2 = r2_score(y_test, y_pred)  # R-squared\n",
    "    mae = mean_absolute_error(y_test, y_pred) # Mean Absolute Error\n",
    "\n",
    "    print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "    print(f'R-squared (R2): {r2:.4f}')\n",
    "    print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "\n",
    "\n",
    "    return y_pred, y_test, r2, mse, mae, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35dc149-0cfc-4c5e-96af-ba5f05717cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1000\n",
    "\n",
    "pred = {}\n",
    "true = {}\n",
    "mse = {}\n",
    "mae = {}\n",
    "r2 = {}\n",
    "bp = {}\n",
    "\n",
    "pred_lin = {}\n",
    "true_lin = {}\n",
    "mse_lin = {}\n",
    "mae_lin = {}\n",
    "r2_lin = {}\n",
    "bp_lin = {}\n",
    "\n",
    "pred_poly = {}\n",
    "true_poly = {}\n",
    "mse_poly = {}\n",
    "mae_poly = {}\n",
    "r2_poly = {}\n",
    "bp_poly = {}\n",
    "\n",
    "kernels = ['rbf', 'lin', 'poly']\n",
    "\n",
    "for kernel in kernels:\n",
    "    for time_bucket in [24,6,2,1]: \n",
    "        for resolution in [6,7,8]:\n",
    "            columnname = f'h:{time_bucket}_res:{resolution}(_{kernel})'\n",
    "            print(columnname)\n",
    "            if resolution == 6:\n",
    "                taxi_df = createdataset(df6, timebucket=time_bucket)\n",
    "            elif resolution == 7:\n",
    "                taxi_df = createdataset(df7, timebucket=time_bucket)\n",
    "            else:\n",
    "                taxi_df = createdataset(df8, timebucket=time_bucket)\n",
    "                \n",
    "            y = taxi_df['demand']\n",
    "            X = taxi_f.drop(['date', 'time_bucket'], axis=1)\n",
    "            \n",
    "            y_p, y_t, r2_v, mse_v, mae_v, best_params_v = trainsvmmodel(X, y, maxiter=iterations, splitratio=0.2, kernel=kernel)\n",
    "\n",
    "            if kernel == 'rbf':\n",
    "                pred[columnname] = y_p\n",
    "                true[columnname] = y_t\n",
    "                mse[columnname ]= mse_v\n",
    "                mae[columnname] = mae_v\n",
    "                r2[columnname] = r2_v\n",
    "                bp[columnname] = best_params_v\n",
    "            elif kernel == 'lin':\n",
    "                pred_lin[columnname] = y_p\n",
    "                true_lin[columnname] = y_t\n",
    "                mse_lin[columnname] = mse\n",
    "                mae_lin[columnname] = mae\n",
    "                r2_lin[columnname] = r2_v\n",
    "                bp_lin[columnname] = best_params_v\n",
    "            elif kernel == 'poly':\n",
    "                pred_poly[columnname] = y_p\n",
    "                true_poly[columnname] = y_t\n",
    "                mse_poly[columnname] = mse\n",
    "                mae_poly[columnname] = mae\n",
    "                r2_poly[columnname] = r2_v\n",
    "                bp_poly[columnname] = best_params_v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13614ff0-f732-47e7-97aa-8f4bc0b4ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store data for the DataFrame\n",
    "data = []\n",
    "\n",
    "# Loop through the kernels\n",
    "for kernel in kernels:\n",
    "    # Loop through time buckets\n",
    "    for time_bucket in [24, 6, 2, 1]:\n",
    "        for resolution in [6, 7, 8]:\n",
    "            columnname = f'h:{time_bucket}_res:{resolution}(_{kernel})'\n",
    "            if kernel=='lin':\n",
    "                r2_score = r2_lin[columnname]\n",
    "                mse = mse_lin[columnname]\n",
    "                mae=mae_lin[columnname]\n",
    "                test_mean = np.mean(pred_lin[columnname])  # Calculate the mean\n",
    "                true_mean = np.mean(true_lin[columnname])\n",
    "                test_var = np.var(pred_lin[columnname])  # Calculate the mean\n",
    "                true_var = np.var(true_lin[columnname])\n",
    "            elif kernel=='rbf':\n",
    "                r2_score = r2[columnname]\n",
    "                mse = mse[columnname]\n",
    "                mae=mae[columnname]\n",
    "                test_mean = np.mean(pred[columnname])  # Calculate the mean\n",
    "                true_mean = np.mean(true[columnname])\n",
    "                test_var = np.var(pred[columnname])  # Calculate the mean\n",
    "                true_var = np.var(true[columnname])\n",
    "            elif kernel=='poly':\n",
    "                r2_score = r2_poly[columnname]\n",
    "                mse = mse_poly[columnname]\n",
    "                mae=mae_poly[columnname]\n",
    "                test_mean = np.mean(pred_poly[columnname])  # Calculate the mean\n",
    "                true_mean = np.mean(true_poly[columnname])\n",
    "                test_var = np.var(pred_poly[columnname])  # Calculate the mean\n",
    "                true_var = np.var(true_poly[columnname])\n",
    "            \n",
    "            data.append({\n",
    "                'Kernel': kernel,\n",
    "                'Hexagon resolution': f'H3-{resolution}',\n",
    "                'Timebucket': time_bucket,\n",
    "                'R2-score': r2_score,\n",
    "                'MSE': mse,\n",
    "                'MAE':mae,\n",
    "                'Test_mean': test_mean,\n",
    "                'Truth_mean': true_mean,\n",
    "                'Test_variance':test_var,\n",
    "                'Truth_var':true_var\n",
    "            })\n",
    "\n",
    "# Create the DataFrame\n",
    "svmresults = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "svmresults"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
